{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ff94845",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RGCN_v1, gwnet_wrapper\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mxai_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m integrated_gradients\n\u001B[1;32m      8\u001B[0m plt\u001B[38;5;241m.\u001B[39mstyle\u001B[38;5;241m.\u001B[39muse(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdark_background\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.models import RGCN_v1, gwnet_wrapper\n",
    "from utils.xai_utils import integrated_gradients\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28427c81",
   "metadata": {},
   "source": [
    "# Set up general arguments and pull in some real River-dl data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39bc706",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define some general arguments for the notebook\n",
    "mod = 'RGCN'  #GWN or RGCN\n",
    "base = 'mean' #zeros or mean\n",
    "grad_steps = 15 #Number of steps to take in calculation of IG\n",
    "year_index = -1 #Sequence to apply IG to\n",
    "weights_file = '../../river-dl/results/baseline/GWN/rep_5/finetuned_weights.pth'\n",
    "prepped_file = \"../../river-dl/results/baseline/GWN/prepped.npz\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "pred_length = 90\n",
    "\n",
    "river_dl = np.load(prepped_file)\n",
    "num_vars = len(river_dl['x_vars'])\n",
    "seq_len = river_dl['x_trn'].shape[1]\n",
    "adj_matrix = river_dl['dist_matrix']\n",
    "n_segs = adj_matrix.shape[0]\n",
    "\n",
    "if base == 'zeros':\n",
    "    x = torch.from_numpy(river_dl['x_trn']).float()[455*year_index:]\n",
    "    baseline = torch.zeros_like(x)\n",
    "\n",
    "elif base == 'mean':\n",
    "    x = torch.from_numpy(river_dl['x_trn']).float()\n",
    "    n_series = river_dl['x_trn'].shape[0]\n",
    "    baseline = x.reshape(n_series//n_segs,n_segs,seq_len,num_vars)\n",
    "    baseline = torch.mean(baseline,dim=0)\n",
    "    x = x[455*year_index:]\n",
    "\n",
    "dates_x = river_dl['times_trn'][455*year_index:][0].flatten()\n",
    "\n",
    "\n",
    "x.shape,baseline.shape, adj_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e1b327",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if mod == 'RGCN':\n",
    "    model = RGCN_v1(num_vars, 20, adj_matrix)\n",
    "    model.load_state_dict(torch.load(weights_file, map_location=device))\n",
    "\n",
    "elif mod == 'GWN':\n",
    "    supports = [torch.tensor(adj_matrix).to(device).float()]\n",
    "    out_dim = pred_length\n",
    "    model = gwnet_wrapper(device,n_segs,supports=supports,aptinit=supports[0],\n",
    "    in_dim=num_vars,out_dim=out_dim,layers=3, kernel_size=5,blocks=3, weights_path=weights_file,\n",
    "                          nsegs=n_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef174b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IG_vals = integrated_gradients(x, model, n_steps=grad_steps, baseline_x=baseline)\n",
    "\n",
    "plt.figure(figsize = (10, 5))\n",
    "for i in range(num_vars):\n",
    "    plt.plot(dates_x, IG_vals[0, :, i], label = river_dl['x_vars'][i])\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.xlabel('Sequence Day')\n",
    "plt.ylabel('IG Value')\n",
    "plt.tight_layout()\n",
    "plt.title('Integrated gradient values at one segment\\nw.r.t. outputs at all space and time',\n",
    "          fontsize = 18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c81fe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IG_vals = integrated_gradients(x,model, n_steps=grad_steps, baseline_x=baseline, temporal_focus = -1)\n",
    "\n",
    "plt.figure(figsize = (10, 5))\n",
    "for i in range(num_vars):\n",
    "    plt.plot(dates_x, IG_vals[0, :, i])\n",
    "plt.title('Integrated gradient values at one segment\\n w.r.t. outputs at all segments but the last time step',\n",
    "          fontsize = 18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0651de",
   "metadata": {},
   "outputs": [],
   "source": [
    "IG_vals = integrated_gradients(x,  model, n_steps=grad_steps, baseline_x=baseline, temporal_focus = -1, spatial_focus = -1)\n",
    "\n",
    "plt.figure(figsize = (10, 5))\n",
    "for i in range(num_vars):\n",
    "    plt.plot(dates_x, IG_vals[0, :, i],label = river_dl['x_vars'][i])\n",
    "plt.legend(loc ='upper left')\n",
    "plt.xlabel('Sequence Day')\n",
    "plt.ylabel('IG Value')\n",
    "plt.tight_layout()\n",
    "plt.title(\"Integrated gradient values at one segment\\n w.r.t. outputs at a different segment's last time step\",\n",
    "          fontsize = 18);\n",
    "\n",
    "plt.figure(figsize = (10, 5))\n",
    "for i in range(num_vars):\n",
    "    plt.plot(dates_x, IG_vals[-1, :, i],label = river_dl['x_vars'][i])\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.xlabel('Sequence Day')\n",
    "plt.ylabel('IG Value')\n",
    "plt.tight_layout()\n",
    "plt.title(\"Integrated gradient values at same segment\\n w.r.t. outputs at that segment's last time step\",\n",
    "          fontsize = 18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac67a73a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "obs = range(1,pred_length, 7)\n",
    "num_plots = len(obs)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_plots,figsize=(11.2,21))\n",
    "for (ob,ax) in zip(reversed(obs),axes):\n",
    "    attributions = integrated_gradients(x,model, n_steps=grad_steps, baseline_x=baseline, temporal_focus = -ob, spatial_focus = -1) # attributions for last day in the sequence\n",
    "    for i in range(num_vars):\n",
    "        ax.plot(dates_x,attributions[0, :, i], label = river_dl['x_vars'][i])\n",
    "    ax.legend(loc = 'upper left')\n",
    "plt.tight_layout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ceec8e",
   "metadata": {},
   "source": [
    "# Apply XAI and visualize - can we trust IG temporally?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14774bec",
   "metadata": {},
   "source": [
    "When looking at what's important for the last time step's prediction, it appears that anything before the last 45 values don't matter. Let's do an experiment where we scramble those supposedly irrelevant values and see how it impacts predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3912d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "IG_vals = integrated_gradients(x,  model, n_steps=grad_steps, baseline_x=baseline, temporal_focus = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81e8965",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "plt.plot(dates_x, IG_vals[-1, :, :])\n",
    "plt.title('Only the last ~60 values seem to matter', fontsize = 20)\n",
    "plt.pause(0.001)\n",
    "plt.figure(figsize = (10, 5))\n",
    "plt.plot(dates_x[-60:], IG_vals[-1, -60:, :]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5709c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    " def compare_temporally_altered(first_n_days):\n",
    "    y_hat_original = model(x)\n",
    "\n",
    "    # replace first n out of 365 days with random values\n",
    "    # and see how results change\n",
    "    x_hypothesis = x.detach().clone()\n",
    "    x_hypothesis[:, :first_n_days] = torch.rand_like(x[:, :first_n_days])\n",
    "    y_hat_hypothesis = model(x_hypothesis)\n",
    "\n",
    "    fig, ax = plt.subplots(3, 2, figsize = (12, 9))\n",
    "\n",
    "    ax[0,0].plot(dates_x, x[0].detach(), color = 'white', alpha = 0.4)\n",
    "    ax[0,0].set_ylim(-3, 5)\n",
    "    ax[0,0].set_title('X Values')\n",
    "    ax[0,1].plot(dates_x, x_hypothesis[0], color = 'white', alpha = 0.4)\n",
    "    ax[0,1].set_ylim(-3, 5)\n",
    "    ax[0,1].set_title('X Values Noised')\n",
    "    ax[1,0].plot(y_hat_original[0].detach())\n",
    "    ax[1,0].set_ylim(-1.5, 1.5)\n",
    "    ax[1,0].set_title('Predicted Values')\n",
    "    ax[1,1].plot(y_hat_hypothesis[0].detach())\n",
    "    ax[1,1].set_ylim(-1.5, 1.5)\n",
    "    ax[1,1].set_title('Predicted Noised')\n",
    "    ax[2,0].plot(y_hat_original[0, :].detach())\n",
    "    ax[2,0].plot(y_hat_hypothesis[0, :].detach())\n",
    "    ax[2,0].set_title('Before and After Noise')\n",
    "    ax[2,1].plot(y_hat_original[0, -60:].detach())\n",
    "    ax[2,1].plot(y_hat_hypothesis[0, -60:].detach())\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9c77bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_temporally_altered(x.shape[1]-60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d79bc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_temporally_altered(x.shape[1]-30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b30a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_temporally_altered(x.shape[1]-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661a82f3",
   "metadata": {},
   "source": [
    "The evidence appears to suggest that we can trust how IG explains importance temporally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55be99c5",
   "metadata": {},
   "source": [
    "# Apply XAI and visualize - can we trust IG spatially?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269548aa",
   "metadata": {},
   "source": [
    "Similar experiment to the above, but seeing if we can trust what neighboring streams are identified as important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160d60ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_spatially_altered(seg_of_interest, important_segments, unimportant_segments):\n",
    "    y_hat_original = model(x)\n",
    "\n",
    "    x_hypothesis1 = x.detach().clone()\n",
    "    for s in important_segments:\n",
    "        x_hypothesis1[s] = torch.rand_like(x[s])\n",
    "    y_hat_hypothesis1 = model(x_hypothesis1)\n",
    "    \n",
    "    x_hypothesis2 = x.detach().clone()\n",
    "    for s in unimportant_segments:\n",
    "        x_hypothesis2[s] = torch.rand_like(x[s])\n",
    "    y_hat_hypothesis2 = model(x_hypothesis2)\n",
    "\n",
    "    fig, ax = plt.subplots(5, figsize = (10, 30))\n",
    "\n",
    "    for seg in important_segments:\n",
    "        ax[0].plot(x[seg].detach(), color = 'white', alpha = 0.3)\n",
    "        ax[1].plot(x_hypothesis1[seg], color = 'white', alpha = 0.5)\n",
    "        ax[1].set_title('Changed segment variable values | important')\n",
    "        \n",
    "    for seg in unimportant_segments:\n",
    "        ax[0].plot(x[seg].detach(), color = 'white', alpha = 0.3)\n",
    "        ax[0].set_title('Unchanged segment variable')\n",
    "        ax[2].plot(x_hypothesis2[seg], color = 'white', alpha = 0.5)\n",
    "        ax[2].set_title('Changed segment variable values | unimportant')\n",
    "    \n",
    "    ax[3].set_title('Predictions under different scenarios')\n",
    "    ax[3].plot(y_hat_original[seg_of_interest, :].detach(),\n",
    "               label = 'Original')\n",
    "    ax[3].plot(y_hat_hypothesis1[seg_of_interest, :].detach(),\n",
    "               label = 'Important segments changed',\n",
    "               linestyle = '--')\n",
    "    ax[3].plot(y_hat_hypothesis2[seg_of_interest, :].detach(),\n",
    "               label = 'Unimportant segments changed',\n",
    "               linestyle = '--')\n",
    "    ax[3].legend()\n",
    "    \n",
    "    ax[4].set_title('Difference in predictions')\n",
    "    ax[4].plot(y_hat_original[seg_of_interest, :].detach() - y_hat_hypothesis1[seg_of_interest, :].detach(),\n",
    "                 label = 'Important segments changed')\n",
    "    ax[4].plot(y_hat_original[seg_of_interest, :].detach() - y_hat_hypothesis2[seg_of_interest, :].detach(),\n",
    "                 label = 'Unimportant segments changed')\n",
    "    ax[4].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e9185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_focus = np.random.choice(455)\n",
    "\n",
    "IG_vals = integrated_gradients(x, model,baseline_x=baseline,n_steps=grad_steps, spatial_focus = spatial_focus)\n",
    "\n",
    "most_relev = np.argsort(-np.sum(np.sum(np.abs(IG_vals), axis = 2), axis = 1))[1:5] # 1:5 because not itself\n",
    "least_relev = np.argsort(-np.sum(np.sum(np.abs(IG_vals), axis = 2), axis = 1))[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb4edba",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_spatially_altered(spatial_focus, most_relev, least_relev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b2d5fb",
   "metadata": {},
   "source": [
    "### A slightly more obvious difference in predictions\n",
    "\n",
    "Spatial information doesn't seem to play a huge role, so hand-picking a more sensitive segment helps show the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b3a942",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_focus = -1\n",
    "\n",
    "IG_vals = integrated_gradients(x,  model,baseline_x=baseline,n_steps=grad_steps, temporal_focus = -1, spatial_focus = spatial_focus)\n",
    "\n",
    "most_relev = np.argsort(-np.sum(np.sum(np.abs(IG_vals), axis = 2), axis = 1))[1:5] # 1:5 because not itself\n",
    "least_relev = np.argsort(-np.sum(np.sum(np.abs(IG_vals), axis = 2), axis = 1))[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36621c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_spatially_altered(spatial_focus, most_relev, least_relev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d93fba",
   "metadata": {},
   "source": [
    "The evidence appears to suggest that we can trust how IG explains importance spatially"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc651b8",
   "metadata": {},
   "source": [
    "# Can we trust the feature importance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aae041",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_focus = 1 # has lots of observations\n",
    "\n",
    "IG_vals = integrated_gradients(x, model, baseline_x=baseline,n_steps=grad_steps, temporal_focus = -1, spatial_focus = 1)\n",
    "\n",
    "plt.figure(figsize = (10, 5))\n",
    "for i in range(num_vars):\n",
    "    plt.plot(dates_x, IG_vals[spatial_focus, :, i], label = river_dl['x_vars'][i], linewidth = 3)\n",
    "#plt.xlim(, 180)\n",
    "plt.legend(loc = 'upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7313b616",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_y_hat = model(x)\n",
    "\n",
    "rmse_ls = []\n",
    "plt.figure(figsize = (10, 5))\n",
    "\n",
    "for i in range(num_vars):\n",
    "    x_hypothesis = x.detach().clone()\n",
    "    x_hypothesis[1, :, i] = torch.rand_like(x_hypothesis[1, :, i]) # change the variables\n",
    "    \n",
    "    y_hypothesis = model(x_hypothesis)\n",
    "    \n",
    "    plt.plot(y_hypothesis[1].detach() - original_y_hat[1].detach(), # view difference in forecast\n",
    "             label = river_dl['x_vars'][i] + ' changed')\n",
    "    #plt.xlim(80,180)\n",
    "    plt.title('Change in forecast; horizontal 0 = no change in forecast')\n",
    "    \n",
    "plt.legend(loc = 'upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b8b2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_importance_of_vars = np.argsort(np.sum(np.abs(IG_vals[1]), axis = 0))\n",
    "\n",
    "mse_ls = []\n",
    "for var in ordered_importance_of_vars:\n",
    "    x_hypothesis = x.detach().clone()\n",
    "    x_hypothesis[1, :, var] = torch.rand_like(x_hypothesis[1, :, var])\n",
    "    y_hypothesis = model(x_hypothesis)\n",
    "    mse = torch.mean((y_hypothesis[1].detach() - original_y_hat[1].detach())**2).item()\n",
    "    mse_ls.append(mse)\n",
    "    \n",
    "plt.scatter(range(len(mse_ls)), mse_ls)\n",
    "plt.xticks(range(len(mse_ls)), labels = river_dl['x_vars'][ordered_importance_of_vars], rotation = 90)\n",
    "plt.title('MSE between original prediction and\\nprediction with altered variable', fontsize = 18)\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Altered variable, more right = IG-determined more important');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1fc763",
   "metadata": {},
   "source": [
    "The experimental results line up pretty well (2 most important variables result in the most forecast change). Not entirely monotonic though, static features and 0-baseline could be playing a role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57030090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}